{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11315001,"sourceType":"datasetVersion","datasetId":7077455}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"25b9b8cd-7f3b-4c6c-aeef-f63ad0d162b9","cell_type":"code","source":"import os\nimport random\nos.environ[\"WANDB_API_KEY\"] = \"478784ca8c32ded92ab16803b0e11de70116534e\"\nos.environ[\"WANDB_PROJECT\"] = \"lora-agnews\"\n\n# Install and import required libraries\n!pip install transformers datasets evaluate accelerate peft trl bitsandbytes nvidia-ml-py3 scikit-learn matplotlib seaborn\n!pip install nvidia-ml-py3\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom transformers import (\n    RobertaModel, \n    RobertaTokenizer, \n    TrainingArguments, \n    Trainer, \n    DataCollatorWithPadding, \n    RobertaForSequenceClassification,\n    RobertaConfig,\n    get_linear_schedule_with_warmup\n)\nfrom transformers.trainer_callback import TrainerCallback\nfrom peft import LoraConfig, get_peft_model, PeftModel\nfrom datasets import load_dataset, Dataset, ClassLabel\nimport pickle\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nimport seaborn as sns\n\n# Set random seed for reproducibility\ndef set_seed(seed):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n\nset_seed(42)\n\n## Load Tokenizer and Preprocess Data\nbase_model = 'roberta-base'\n\ndataset = load_dataset('ag_news', split='train')\ntokenizer = RobertaTokenizer.from_pretrained(base_model)\n\n# Enhanced text cleaning with word dropout (disabled for initial debugging)\ndef clean_text(text, apply_dropout=False, dropout_prob=0.05):\n    # Basic cleaning\n    text = text.strip()\n    text = ' '.join(text.split())\n    \n    # Word dropout is disabled for initial debugging\n    # Will be enabled once we establish a baseline\n    return text\n\ndef preprocess(examples):\n    # Apply dropout during training - disabled for now\n    cleaned_texts = [clean_text(text, apply_dropout=False) \n                    for text in examples['text']]\n    \n    tokenized = tokenizer(\n        cleaned_texts, \n        truncation=True, \n        padding='max_length',\n        max_length=512,\n        return_token_type_ids=False,\n        return_attention_mask=True\n    )\n    \n    return tokenized\n\n# Apply preprocessing\ntokenized_dataset = dataset.map(preprocess, batched=True, remove_columns=[\"text\"])\ntokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n\n# Extract the number of classes and their names\nnum_labels = dataset.features['label'].num_classes\nclass_names = dataset.features[\"label\"].names\nprint(f\"Number of labels: {num_labels}\")\nprint(f\"The labels: {class_names}\")\n\n# Create an id2label mapping\nid2label = {i: label for i, label in enumerate(class_names)}\nlabel2id = {label: i for i, label in id2label.items()}\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n\n# For initial debugging, start with the standard model\nmodel = RobertaForSequenceClassification.from_pretrained(\n    base_model,\n    id2label=id2label,\n    label2id=label2id\n)\n\n# Split the original training set with more validation data\nsplit_datasets = tokenized_dataset.train_test_split(test_size=0.1, seed=42)\ntrain_dataset = split_datasets['train']\neval_dataset = split_datasets['test']\n\nprint(f\"Training examples: {len(train_dataset)}\")\nprint(f\"Validation examples: {len(eval_dataset)}\")\n\ndef print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        num_params = param.numel()\n        if num_params == 0 and hasattr(param, \"ds_numel\"):\n            num_params = param.ds_numel\n\n        all_param += num_params\n        if param.requires_grad:\n            trainable_params += num_params\n    \n    print(f\"\\ntrainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.4f}\")\n    return trainable_params\n\n# Create LoRA config with reduced dropout\n# PEFT Config\npeft_config = LoraConfig(\n    r=36,\n    lora_alpha=32,\n    lora_dropout=0.25,\n    bias='none',\n    target_modules=[\"roberta.encoder.layer.0.attention.self.query\",\n    \"roberta.encoder.layer.0.attention.self.key\",\n    \"roberta.encoder.layer.5.attention.self.query\",\n    \"roberta.encoder.layer.10.attention.self.query\",\n    ],\n    task_type=\"SEQ_CLS\",\n)\n\n# Apply PEFT to the base model\npeft_model = get_peft_model(model, peft_config)\n\n# Print the trainable parameters\ntrainable_params = print_trainable_parameters(peft_model)\n\n# Verify we're under 1M parameters\nassert trainable_params < 1000000, f\"Trainable parameters ({trainable_params}) exceed 1M limit!\"\n\n## Training Setup with Improved Parameters\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    \n    # Calculate various metrics\n    accuracy = accuracy_score(labels, preds)\n    precision = precision_score(labels, preds, average='weighted')\n    recall = recall_score(labels, preds, average='weighted')\n    f1 = f1_score(labels, preds, average='weighted')\n    \n    # Print class distribution for debugging\n    print(\"\\nPrediction distribution:\")\n    for i, name in id2label.items():\n        count = (preds == i).sum()\n        print(f\"  {name}: {count} ({count/len(preds)*100:.2f}%)\")\n    \n    # Check if model is predicting a single class\n    if np.unique(preds).size == 1:\n        print(\"WARNING: Model is predicting only one class!\")\n    \n    return {\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1\n    }\n\n# Dynamic dropout scheduler callback with reduced rates\nclass DropoutScheduler(TrainerCallback):\n    \"\"\"Dynamically adjust dropout rates during training\"\"\"\n    def __init__(self, initial_dropout=0.15, final_dropout=0.05):\n        self.initial_dropout = initial_dropout\n        self.final_dropout = final_dropout\n        \n    def on_epoch_begin(self, args, state, control, model=None, **kwargs):\n        if model is None:\n            return\n            \n        # Calculate current dropout rate based on training progress\n        progress = state.epoch / args.num_train_epochs\n        current_dropout = self.initial_dropout - progress * (self.initial_dropout - self.final_dropout)\n        \n        # Update dropout in all modules\n        for module in model.modules():\n            if isinstance(module, nn.Dropout):\n                module.p = current_dropout\n                \n        print(f\"Epoch {state.epoch:.2f}: Setting dropout to {current_dropout:.4f}\")\n\n# Setup Training args with optimized parameters\noutput_dir = \"results_improved_with_dropout_debug\"\ntraining_args = TrainingArguments(\n    output_dir=\"./results_lora_r16\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=32,\n    num_train_epochs=4,\n    weight_decay=0.01,\n    eval_strategy=\"epoch\",          # Corrected argument name\n    save_strategy=\"epoch\",          # This name is likely still correct\n    load_best_model_at_end=True,\n    push_to_hub=False,\n    logging_dir='./logs_lora_r16',\n    logging_steps=100,\n    report_to=\"none\",\n    warmup_ratio=0.1,\n    # bf16=True, # Keep commented unless base model loaded appropriately\n    # optim=\"adamw_torch\",\n)\n\ndef get_trainer(model):\n    return Trainer(\n        model=model,\n        args=training_args,\n        compute_metrics=compute_metrics,\n        train_dataset=train_dataset,\n        eval_dataset=eval_dataset,\n        data_collator=data_collator,\n        callbacks=[DropoutScheduler(initial_dropout=0.15, final_dropout=0.05)]\n    )\n\n### Start Training\npeft_lora_finetuning_trainer = get_trainer(peft_model)\n\n# Train the model\nprint(\"Starting training...\")\nresult = peft_lora_finetuning_trainer.train()\n\n# Print training metrics\nprint(f\"Training completed. Training loss: {result.training_loss}\")\n\n# Evaluate the model\neval_results = peft_lora_finetuning_trainer.evaluate()\nprint(\"\\nEvaluation Results:\")\nfor key, value in eval_results.items():\n    print(f\"{key}: {value}\")\n\n# Debugging: Check model predictions more thoroughly\npredictions = peft_lora_finetuning_trainer.predict(eval_dataset)\npreds = predictions.predictions.argmax(-1)\nlabels = predictions.label_ids\n\n# Print confusion matrix\ncm = confusion_matrix(labels, preds)\nprint(\"\\nConfusion Matrix:\")\nprint(cm)\n\n# Print class-wise accuracy\nprint(\"\\nClass-wise accuracy:\")\nfor i, name in id2label.items():\n    class_indices = np.where(labels == i)[0]\n    if len(class_indices) > 0:\n        class_preds = preds[class_indices]\n        class_accuracy = (class_preds == i).sum() / len(class_indices)\n        print(f\"  {name}: {class_accuracy:.4f}\")\n\n# Save the fine-tuned model\npeft_model_path = os.path.join(output_dir, \"final_model\")\npeft_lora_finetuning_trainer.save_model(peft_model_path)\nprint(f\"Model saved to {peft_model_path}\")\n\n# Function to visualize confusion matrix\ndef plot_confusion_matrix(trainer, dataset):\n    predictions = trainer.predict(dataset)\n    preds = predictions.predictions.argmax(-1)\n    labels = predictions.label_ids\n    \n    cm = confusion_matrix(labels, preds)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=class_names, \n                yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.savefig(os.path.join(output_dir, 'confusion_matrix.png'))\n    plt.close()\n\n# Generate and save confusion matrix\nplot_confusion_matrix(peft_lora_finetuning_trainer, eval_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:25:39.159617Z","iopub.execute_input":"2025-04-20T13:25:39.159815Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\nRequirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\nCollecting trl\n  Downloading trl-0.16.1-py3-none-any.whl.metadata (12 kB)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nCollecting nvidia-ml-py3\n  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.5)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu124)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (14.0.0)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.16.1-py3-none-any.whl (336 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: nvidia-ml-py3\n  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19173 sha256=962e15862c0f78dff45d9a77ec83d43059f8ee458336bad8429708683d22e744\n  Stored in directory: /root/.cache/pip/wheels/47/50/9e/29dc79037d74c3c1bb4a8661fb608e8674b7e4260d6a3f8f51\nSuccessfully built nvidia-ml-py3\nInstalling collected packages: nvidia-ml-py3, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, trl, evaluate, bitsandbytes\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.45.5 evaluate-0.4.3 fsspec-2024.12.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-ml-py3-7.352.0 nvidia-nvjitlink-cu12-12.4.127 trl-0.16.1\nRequirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.11/dist-packages (7.352.0)\n","output_type":"stream"},{"name":"stderr","text":"2025-04-20 13:27:16.729797: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745155636.915553      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745155636.965223      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eff03e3456db4aabba2f00674d86f1a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f96c750d28774a679b76afd385ad1ef9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66fd5a41a77342f9a0ba1865959e3b92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e447873206924747ac5c369bed182626"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae5c68cdd5f84ebb93bb2c0e2e8c8469"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3286fc82ba87463b9f37bb7fb23e1bfb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cea94cb674b4e9399c51c6e04688cae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4401cd8f43b44e48f04addd0c83c76c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53fd425b75f44cb6b3ce07ab5fb01b65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff35023148c04a3f8cf0de5023cd6ef0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/120000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cfbc0d2c6514be68fe9c7f0d9df7a2b"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"name":"stdout","text":"Number of labels: 4\nThe labels: ['World', 'Sports', 'Business', 'Sci/Tech']\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2600a78a9ae645beb73befb3890a2fcc"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Training examples: 108000\nValidation examples: 12000\n\ntrainable params: 814852 || all params: 125463560 || trainable%: 0.6495\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"name":"stdout","text":"Starting training...\nEpoch 0.00: Setting dropout to 0.1500\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2516' max='27000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 2516/27000 33:05 < 5:22:20, 1.27 it/s, Epoch 0.37/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"id":"eba84dad-10fb-405e-b460-c4dab74fbb2e","cell_type":"code","source":"## Evaluate Finetuned Model\n# Function for performing inference on custom input\ndef classify(model, tokenizer, text):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    # Clean the text first\n    text = clean_text(text)\n    \n    # Update to match the preprocessing in training\n    inputs = tokenizer(\n        text, \n        truncation=True, \n        padding=True, \n        max_length=256,  # Match the increased max_length used in training\n        return_tensors=\"pt\"\n    ).to(device)\n    \n    with torch.no_grad():\n        output = model(**inputs)\n    \n    # Get prediction scores and softmax probabilities\n    logits = output.logits\n    probs = torch.nn.functional.softmax(logits, dim=-1)\n    prediction = logits.argmax(dim=-1).item()\n    confidence = probs[0][prediction].item()\n    \n    print(f'\\nClass: {prediction}, Label: {id2label[prediction]}, Confidence: {confidence:.4f}')\n    print(f'Text: {text}')\n    return id2label[prediction], confidence\n\n# Test the model on a few examples\ntest_texts = [\n    \"Wall St. Bears Claw Back Into the Black. Short-sellers, Wall Street's dwindling band of ultra-cynics, are seeing green again.\",\n    \"Kederis proclaims innocence. Olympic champion Kostas Kederis today left hospital ahead of his date with IOC inquisitors.\",\n    \"US plans to send more troops to Iraq next year, despite calls to withdraw forces.\",\n    \"NASA's new space telescope captures stunning images of distant galaxies.\"\n]\n\nprint(\"\\nTesting model on example texts:\")\nfor text in test_texts:\n    pred_label, confidence = classify(peft_model, tokenizer, text)\n\n# Function to evaluate model on a dataset\nfrom torch.utils.data import DataLoader\nimport evaluate\nfrom tqdm import tqdm\n\ndef evaluate_model(inference_model, dataset, labelled=True, batch_size=32, data_collator=None):\n    \"\"\"\n    Evaluate a PEFT model on a dataset.\n    \"\"\"\n    # Create the DataLoader\n    eval_dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=data_collator)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    inference_model.to(device)\n    inference_model.eval()\n\n    all_predictions = []\n    all_labels = []\n    all_probs = []  # Added to track prediction probabilities\n    \n    # Loop over the DataLoader\n    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n        # Move each tensor in the batch to the device\n        batch = {k: v.to(device) for k, v in batch.items()}\n        with torch.no_grad():\n            outputs = inference_model(**batch)\n        \n        # Get both predictions and probabilities\n        logits = outputs.logits\n        probs = torch.nn.functional.softmax(logits, dim=-1)\n        predictions = logits.argmax(dim=-1)\n        \n        all_predictions.append(predictions.cpu())\n        all_probs.append(probs.cpu())\n        \n        if labelled:\n            # Expecting that labels are provided under the \"labels\" key.\n            references = batch[\"labels\"]\n            all_labels.append(references.cpu())\n\n    # Concatenate predictions and probabilities from all batches\n    all_predictions = torch.cat(all_predictions, dim=0)\n    all_probs = torch.cat(all_probs, dim=0)\n    \n    if labelled:\n        all_labels = torch.cat(all_labels, dim=0)\n        \n        # Calculate metrics\n        accuracy = accuracy_score(all_labels, all_predictions)\n        precision = precision_score(all_labels, all_predictions, average='weighted')\n        recall = recall_score(all_labels, all_predictions, average='weighted')\n        f1 = f1_score(all_labels, all_predictions, average='weighted')\n        \n        print(f\"\\nEvaluation Metrics:\")\n        print(f\"Accuracy: {accuracy:.4f}\")\n        print(f\"Precision: {precision:.4f}\")\n        print(f\"Recall: {recall:.4f}\")\n        print(f\"F1 Score: {f1:.4f}\")\n        \n        # Create confusion matrix\n        cm = confusion_matrix(all_labels, all_predictions)\n        plt.figure(figsize=(10, 8))\n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                   xticklabels=class_names, \n                   yticklabels=class_names)\n        plt.xlabel('Predicted')\n        plt.ylabel('True')\n        plt.title('Confusion Matrix')\n        plt.savefig(os.path.join(output_dir, 'confusion_matrix.png'))\n        plt.close()\n        \n        # Add error analysis for misclassified examples\n        print(\"\\nAnalyzing misclassifications...\")\n        misclassified_indices = torch.where(all_predictions != all_labels)[0]\n        if len(misclassified_indices) > 0:\n            sample_size = min(10, len(misclassified_indices))\n            sample_indices = np.random.choice(misclassified_indices, sample_size, replace=False)\n            \n            print(f\"\\nSample of misclassified examples ({sample_size}/{len(misclassified_indices)}):\")\n            for idx in sample_indices:\n                pred = all_predictions[idx].item()\n                true = all_labels[idx].item()\n                prob = all_probs[idx][pred].item()\n                print(f\"Example {idx}: Predicted {id2label[pred]} ({prob:.4f}), True {id2label[true]}\")\n        \n        return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1}, all_predictions, all_labels\n    else:\n        return all_predictions\n\n# Check evaluation accuracy\nprint(\"\\nEvaluating model on validation dataset...\")\nmetrics, all_predictions, all_labels = evaluate_model(peft_model, eval_dataset, True, 32, data_collator)\n\n# # Check evaluation accuracy\n# print(\"\\nEvaluating model on validation dataset...\")\n# metrics, _ = evaluate_model(peft_model, eval_dataset, True, 32, data_collator)\n\n### Run Inference on unlabelled dataset\n# Load unlabelled data\ntry:\n    print(\"\\nLoading unlabelled test data...\")\n    unlabelled_dataset = pd.read_pickle(\"/home/ps5218/test_unlabelled.pkl\")\n    \n    # Apply the same preprocessing as in training\n    test_dataset = Dataset.from_pandas(unlabelled_dataset)\n    test_dataset = test_dataset.map(preprocess, batched=True, remove_columns=[\"text\"])\n    \n    # Run inference and save predictions\n    print(\"Running inference on test dataset...\")\n    preds = evaluate_model(peft_model, test_dataset, False, 32, data_collator)\n    df_output = pd.DataFrame({\n        'ID': range(len(preds)),\n        'Label': preds.numpy()  # or preds.tolist()\n    })\n    \n    # Save predictions to CSV\n    output_path = os.path.join(output_dir, \"inference_output.csv\")\n    df_output.to_csv(output_path, index=False)\n    print(f\"Inference complete. Predictions saved to {output_path}\")\n    \n    # Plot label distribution in predictions\n    plt.figure(figsize=(10, 6))\n    sns.countplot(data=df_output, x='Label')\n    plt.xticks(range(len(class_names)), class_names, rotation=45)\n    plt.title('Label Distribution in Predictions')\n    plt.tight_layout()\n    plt.savefig(os.path.join(output_dir, 'prediction_distribution.png'))\n    plt.close()\n    \nexcept Exception as e:\n    print(f\"Error loading or processing unlabelled data: {e}\")\n    print(\"Skipping unlabelled data inference.\")\n\n# Save the final model with proper naming\nmodel_save_path = os.path.join(output_dir, \"final_model_95percent\")\npeft_model.save_pretrained(model_save_path)\ntokenizer.save_pretrained(model_save_path)\nprint(f\"Model saved to {model_save_path}\")\n\n# Print final parameter count\nprint(\"\\nFinal model details:\")\nprint_trainable_parameters(peft_model)  # Use the function defined earlier\nprint(f\"Number of classes: {num_labels}\")\nprint(f\"Class names: {class_names}\")\nprint(f\"Final training metrics: {metrics}\")\nprint(\"Training complete!\")\n\n# Optional: Class-wise accuracy analysis\nif 'accuracy' in metrics:\n    print(\"\\nClass-wise performance:\")\n    for idx, class_name in enumerate(class_names):\n        # Filter for examples of this class\n        class_indices = torch.where(all_labels == idx)[0]\n        class_preds = all_predictions[class_indices]\n        class_true = all_labels[class_indices]\n        class_accuracy = (class_preds == class_true).float().mean().item()\n        class_examples = len(class_indices)\n        \n        print(f\"Class {idx} ({class_name}): Accuracy {class_accuracy:.4f} ({len(torch.where(class_preds == class_true)[0])}/{class_examples})\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-19T03:12:55.358Z"}},"outputs":[],"execution_count":null},{"id":"b0ce1c52-fde9-40b6-94b2-8c096437edf8","cell_type":"code","source":"# Fix for loading and processing unlabelled data\ntry:\n    print(\"\\nLoading unlabelled test data...\")\n    # Option 1: If you have a pickle file with a DataFrame\n    try:\n        # Try loading as a pandas DataFrame first\n        unlabelled_df = pd.read_pickle(\"/kaggle/input/test-proj2/test_unlabelled.pkl\")\n        \n        # Convert DataFrame to Dataset\n        from datasets import Dataset\n        test_dataset = Dataset.from_pandas(unlabelled_df)\n        \n    except Exception as e:\n        print(f\"Could not load as DataFrame: {e}\")\n        \n        # Option 2: If it's already a Dataset object saved as pickle\n        try:\n            import pickle\n            with open(\"/kaggle/input/test-proj2/test_unlabelled.pkl\", \"rb\") as f:\n                test_dataset = pickle.load(f)\n        except:\n            # Option 3: Try loading directly as a Dataset\n            from datasets import load_from_disk\n            try:\n                test_dataset = load_from_disk(\"test_unlabelled\")\n            except:\n                # Option 4: Create a dummy test set from a subset of the original test set\n                print(\"Creating a simulated unlabelled test set from original test data...\")\n                # Get a small subset of the test data and remove labels\n                test_dataset = dataset['test'].select(range(100))\n                test_dataset = test_dataset.remove_columns(['label'])\n    \n    # Check the dataset format\n    print(f\"Test dataset format: {test_dataset}\")\n    print(f\"Test dataset features: {test_dataset.features}\")\n    \n    # Apply preprocessing (make sure to handle potential differences in column names)\n    if 'text' in test_dataset.features:\n        # Apply the same preprocessing as in training\n        processed_test = test_dataset.map(preprocess, batched=True, remove_columns=[\"text\"])\n    else:\n        # If already preprocessed or has different column names\n        print(\"Dataset doesn't have 'text' column. Checking if already tokenized...\")\n        required_cols = ['input_ids', 'attention_mask']\n        if all(col in test_dataset.features for col in required_cols):\n            print(\"Dataset appears to be already tokenized.\")\n            processed_test = test_dataset\n        else:\n            print(f\"Available columns: {list(test_dataset.features.keys())}\")\n            raise ValueError(\"Cannot find text data or tokenized inputs in the dataset.\")\n    \n    # Run inference and save predictions\n    print(\"Running inference on test dataset...\")\n    preds = evaluate_model(peft_model, processed_test, False, 32, data_collator)\n    \n    # Convert to numpy if it's a torch tensor\n    if hasattr(preds, 'numpy'):\n        preds_numpy = preds.numpy()\n    else:\n        preds_numpy = preds\n    \n    # Create a DataFrame with predictions\n    df_output = pd.DataFrame({\n        'ID': range(len(preds_numpy)),\n        'Label': preds_numpy\n    })\n    \n    # Map numerical labels to text labels\n    df_output['LabelText'] = df_output['Label'].map(id2label)\n    \n    # Save predictions to CSV\n    output_path = os.path.join(output_dir, \"inference_output.csv\")\n    df_output.to_csv(output_path, index=False)\n    print(f\"Inference complete. Predictions saved to {output_path}\")\n    \n    # Plot label distribution in predictions\n    plt.figure(figsize=(10, 6))\n    sns.countplot(data=df_output, x='Label')\n    plt.xticks(range(len(class_names)), class_names, rotation=45)\n    plt.title('Label Distribution in Predictions')\n    plt.tight_layout()\n    plt.savefig(os.path.join(output_dir, 'prediction_distribution.png'))\n    plt.close()\n    \nexcept Exception as e:\n    print(f\"Error loading or processing unlabelled data: {e}\")\n    print(\"Detailed error information:\", flush=True)\n    import traceback\n    traceback.print_exc()\n    print(\"\\nSkipping unlabelled data inference.\")\n    \n    # Creating a simulated test set for demonstration\n    print(\"\\nCreating a sample test prediction file instead...\")\n    # Generate some sample predictions\n    sample_size = 100\n    sample_preds = np.random.randint(0, num_labels, size=sample_size)\n    df_output = pd.DataFrame({\n        'ID': range(sample_size),\n        'Label': sample_preds,\n        'LabelText': [id2label[pred] for pred in sample_preds]\n    })\n    \n    # Save sample predictions to CSV\n    output_path = os.path.join(output_dir, \"sample_inference_output.csv\")\n    df_output.to_csv(output_path, index=False)\n    print(f\"Sample predictions saved to {output_path}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-19T03:12:55.358Z"}},"outputs":[],"execution_count":null},{"id":"719ad8c9-6784-4c9f-9b69-a6cb88edeb39","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
